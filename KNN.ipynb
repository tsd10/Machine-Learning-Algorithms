{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfpPwawM5D/n28dRk/IKoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsd10/Machine-Learning-Algorithms/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***KNN Algorithm:***\n",
        "\n",
        "K-Nearest Neighbour is a type of supervised learning based classification algorithm. \n",
        "\n",
        "* Lazy learning algorithm − KNN is a lazy learning algorithm because it does not have a specialized training phase and uses all the data for training while classification.\n",
        "* Non-parametric learning algorithm − KNN is also a non-parametric learning algorithm because it doesn’t assume anything about the underlying data.\n",
        "\n",
        "Working of KNN:\n",
        "\n",
        "\n",
        "1. After loading the test data, we choose the integer value K (i.e. the nearest data points). \n",
        "2. For each point in the test data we need to perform. Calculate the distance between test data and each row of training data with the help of any of the method namely: Euclidean, Manhattan or Hamming distance. The most commonly used method to calculate distance is Euclidean.\n",
        "3. Now, based on the distance value, sort them in ascending order.\n",
        "4. Next, it will choose the top K rows from the sorted array.\n",
        "5. Now, it will assign a class to the test point based on most frequent class of these rows.\n",
        "\n",
        "    \n",
        "  \n",
        "Reference: https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zKI8JNVQKVr7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "281wZotNxC7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f09f20-6e62-4e78-bbe3-92caa7ba1588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[14  0  0]\n",
            " [ 0 23  0]\n",
            " [ 0  3 20]]\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        14\n",
            "Iris-versicolor       0.88      1.00      0.94        23\n",
            " Iris-virginica       1.00      0.87      0.93        23\n",
            "\n",
            "       accuracy                           0.95        60\n",
            "      macro avg       0.96      0.96      0.96        60\n",
            "   weighted avg       0.96      0.95      0.95        60\n",
            "\n",
            "Accuracy: 0.95\n"
          ]
        }
      ],
      "source": [
        "# KNN as Classifier\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "headernames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "dataset = pd.read_csv(path, names = headernames)\n",
        "dataset.head()\n",
        "\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 8)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "result = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(result)\n",
        "result1 = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\",)\n",
        "print (result1)\n",
        "result2 = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy:\",result2)\n"
      ]
    }
  ]
}